{"ast":null,"code":"\"use strict\";\n\n/*\n * Copyright 2017 Google Inc. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.ImprovedStreamingClient = void 0;\nconst common = require(\"@google-cloud/common\");\nconst pumpify = require(\"pumpify\");\nconst streamEvents = require(\"stream-events\");\nconst stream_1 = require(\"stream\");\nclass ImprovedStreamingClient {\n  /**\n   * Performs bidirectional streaming speech recognition: receive results while\n   * sending audio. This method is only available via the gRPC API (not REST).\n   *\n   * @param {object} config The configuration for the stream. This is\n   *     appropriately wrapped and sent as the first argument. It should be an\n   *     object conforming to the [StreamingRecognitionConfig]{@link StreamingRecognitionConfig}\n   *     structure.\n   * @param {object} [options] Optional parameters. You can override the default\n   *     settings for this call, e.g, timeout, retries, paginations, etc. See\n   *     [gax.CallOptions]{@link https://googleapis.github.io/gax-nodejs/global.html#CallOptions}\n   *     for the details.\n   * @returns {stream} An object stream which is both readable and writable. It\n   *     accepts raw audio for the `write()` method, and will emit objects\n   *     representing [StreamingRecognizeResponse]{@link StreamingRecognizeResponse}\n   *     on the 'data' event asynchronously.\n   *\n   * @example\n   * const speech = require('@google-cloud/speech');\n   * const client = new speech.SpeechClient();\n   *\n   * const stream = client.streamingRecognize({\n   *   config: {\n   *     encoding: 'LINEAR16',\n   *     languageCode: 'en-us',\n   *     sampleRateHertz: 44100,\n   *   },\n   * }).on('data', function(response) {\n   *   // doThingsWith(response);\n   * });\n   * const request = {};\n   * // Write request objects.\n   * stream.write(request);\n   */\n  streamingRecognize(streamingConfig, options) {\n    options = options || {};\n    streamingConfig = streamingConfig || {};\n    // Format the audio content as input request for pipeline\n    const recognizeStream = streamEvents(new pumpify.obj());\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const requestStream = this._streamingRecognize(options).on('error', err => {\n      recognizeStream.destroy(err);\n    }).on('response', response => {\n      recognizeStream.emit('response', response);\n    });\n    // Attach the events to the request stream, but only do so\n    // when the first write (of data) comes in.\n    //\n    // This also means that the sending of the initial request (with the\n    // config) is delayed until we get the first burst of data.\n    recognizeStream.once('writing', () => {\n      // The first message should contain the streaming config.\n      requestStream.write({\n        streamingConfig\n      });\n      // Set up appropriate piping between the stream returned by\n      // the underlying API method and the one that we return.\n      recognizeStream.setPipeline([\n      // Format the user's input.\n      // This entails that the user sends raw audio; it is wrapped in\n      // the appropriate request structure.\n      new stream_1.PassThrough({\n        objectMode: true,\n        transform: (audioContent, _, next) => {\n          if (audioContent !== undefined) {\n            next(undefined, {\n              audioContent\n            });\n            return;\n          }\n          next();\n        }\n      }), requestStream, new stream_1.PassThrough({\n        objectMode: true,\n        transform: (response, enc, next) => {\n          if (response.error) {\n            next(new common.util.ApiError(response.error));\n            return;\n          }\n          next(undefined, response);\n        }\n      })]);\n    });\n    return recognizeStream;\n  }\n}\nexports.ImprovedStreamingClient = ImprovedStreamingClient;","map":{"version":3,"names":["Object","defineProperty","exports","value","ImprovedStreamingClient","common","require","pumpify","streamEvents","stream_1","streamingRecognize","streamingConfig","options","recognizeStream","obj","requestStream","_streamingRecognize","on","err","destroy","response","emit","once","write","setPipeline","PassThrough","objectMode","transform","audioContent","_","next","undefined","enc","error","util","ApiError"],"sources":["C:/Users/anany/OneDrive/Desktop/DTI/frontend/node_modules/@google-cloud/speech/build/src/helpers.js"],"sourcesContent":["\"use strict\";\n/*\n * Copyright 2017 Google Inc. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ImprovedStreamingClient = void 0;\nconst common = require(\"@google-cloud/common\");\nconst pumpify = require(\"pumpify\");\nconst streamEvents = require(\"stream-events\");\nconst stream_1 = require(\"stream\");\nclass ImprovedStreamingClient {\n    /**\n     * Performs bidirectional streaming speech recognition: receive results while\n     * sending audio. This method is only available via the gRPC API (not REST).\n     *\n     * @param {object} config The configuration for the stream. This is\n     *     appropriately wrapped and sent as the first argument. It should be an\n     *     object conforming to the [StreamingRecognitionConfig]{@link StreamingRecognitionConfig}\n     *     structure.\n     * @param {object} [options] Optional parameters. You can override the default\n     *     settings for this call, e.g, timeout, retries, paginations, etc. See\n     *     [gax.CallOptions]{@link https://googleapis.github.io/gax-nodejs/global.html#CallOptions}\n     *     for the details.\n     * @returns {stream} An object stream which is both readable and writable. It\n     *     accepts raw audio for the `write()` method, and will emit objects\n     *     representing [StreamingRecognizeResponse]{@link StreamingRecognizeResponse}\n     *     on the 'data' event asynchronously.\n     *\n     * @example\n     * const speech = require('@google-cloud/speech');\n     * const client = new speech.SpeechClient();\n     *\n     * const stream = client.streamingRecognize({\n     *   config: {\n     *     encoding: 'LINEAR16',\n     *     languageCode: 'en-us',\n     *     sampleRateHertz: 44100,\n     *   },\n     * }).on('data', function(response) {\n     *   // doThingsWith(response);\n     * });\n     * const request = {};\n     * // Write request objects.\n     * stream.write(request);\n     */\n    streamingRecognize(streamingConfig, options) {\n        options = options || {};\n        streamingConfig = streamingConfig || {};\n        // Format the audio content as input request for pipeline\n        const recognizeStream = streamEvents(new pumpify.obj());\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const requestStream = this\n            ._streamingRecognize(options)\n            .on('error', (err) => {\n            recognizeStream.destroy(err);\n        })\n            .on('response', (response) => {\n            recognizeStream.emit('response', response);\n        });\n        // Attach the events to the request stream, but only do so\n        // when the first write (of data) comes in.\n        //\n        // This also means that the sending of the initial request (with the\n        // config) is delayed until we get the first burst of data.\n        recognizeStream.once('writing', () => {\n            // The first message should contain the streaming config.\n            requestStream.write({ streamingConfig });\n            // Set up appropriate piping between the stream returned by\n            // the underlying API method and the one that we return.\n            recognizeStream.setPipeline([\n                // Format the user's input.\n                // This entails that the user sends raw audio; it is wrapped in\n                // the appropriate request structure.\n                new stream_1.PassThrough({\n                    objectMode: true,\n                    transform: (audioContent, _, next) => {\n                        if (audioContent !== undefined) {\n                            next(undefined, { audioContent });\n                            return;\n                        }\n                        next();\n                    },\n                }),\n                requestStream,\n                new stream_1.PassThrough({\n                    objectMode: true,\n                    transform: (response, enc, next) => {\n                        if (response.error) {\n                            next(new common.util.ApiError(response.error));\n                            return;\n                        }\n                        next(undefined, response);\n                    },\n                }),\n            ]);\n        });\n        return recognizeStream;\n    }\n}\nexports.ImprovedStreamingClient = ImprovedStreamingClient;\n//# sourceMappingURL=helpers.js.map"],"mappings":"AAAA,YAAY;;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAA,MAAM,CAACC,cAAc,CAACC,OAAO,EAAE,YAAY,EAAE;EAAEC,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DD,OAAO,CAACE,uBAAuB,GAAG,KAAK,CAAC;AACxC,MAAMC,MAAM,GAAGC,OAAO,CAAC,sBAAsB,CAAC;AAC9C,MAAMC,OAAO,GAAGD,OAAO,CAAC,SAAS,CAAC;AAClC,MAAME,YAAY,GAAGF,OAAO,CAAC,eAAe,CAAC;AAC7C,MAAMG,QAAQ,GAAGH,OAAO,CAAC,QAAQ,CAAC;AAClC,MAAMF,uBAAuB,CAAC;EAC1B;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACIM,kBAAkB,CAACC,eAAe,EAAEC,OAAO,EAAE;IACzCA,OAAO,GAAGA,OAAO,IAAI,CAAC,CAAC;IACvBD,eAAe,GAAGA,eAAe,IAAI,CAAC,CAAC;IACvC;IACA,MAAME,eAAe,GAAGL,YAAY,CAAC,IAAID,OAAO,CAACO,GAAG,EAAE,CAAC;IACvD;IACA,MAAMC,aAAa,GAAG,IAAI,CACrBC,mBAAmB,CAACJ,OAAO,CAAC,CAC5BK,EAAE,CAAC,OAAO,EAAGC,GAAG,IAAK;MACtBL,eAAe,CAACM,OAAO,CAACD,GAAG,CAAC;IAChC,CAAC,CAAC,CACGD,EAAE,CAAC,UAAU,EAAGG,QAAQ,IAAK;MAC9BP,eAAe,CAACQ,IAAI,CAAC,UAAU,EAAED,QAAQ,CAAC;IAC9C,CAAC,CAAC;IACF;IACA;IACA;IACA;IACA;IACAP,eAAe,CAACS,IAAI,CAAC,SAAS,EAAE,MAAM;MAClC;MACAP,aAAa,CAACQ,KAAK,CAAC;QAAEZ;MAAgB,CAAC,CAAC;MACxC;MACA;MACAE,eAAe,CAACW,WAAW,CAAC;MACxB;MACA;MACA;MACA,IAAIf,QAAQ,CAACgB,WAAW,CAAC;QACrBC,UAAU,EAAE,IAAI;QAChBC,SAAS,EAAE,CAACC,YAAY,EAAEC,CAAC,EAAEC,IAAI,KAAK;UAClC,IAAIF,YAAY,KAAKG,SAAS,EAAE;YAC5BD,IAAI,CAACC,SAAS,EAAE;cAAEH;YAAa,CAAC,CAAC;YACjC;UACJ;UACAE,IAAI,EAAE;QACV;MACJ,CAAC,CAAC,EACFf,aAAa,EACb,IAAIN,QAAQ,CAACgB,WAAW,CAAC;QACrBC,UAAU,EAAE,IAAI;QAChBC,SAAS,EAAE,CAACP,QAAQ,EAAEY,GAAG,EAAEF,IAAI,KAAK;UAChC,IAAIV,QAAQ,CAACa,KAAK,EAAE;YAChBH,IAAI,CAAC,IAAIzB,MAAM,CAAC6B,IAAI,CAACC,QAAQ,CAACf,QAAQ,CAACa,KAAK,CAAC,CAAC;YAC9C;UACJ;UACAH,IAAI,CAACC,SAAS,EAAEX,QAAQ,CAAC;QAC7B;MACJ,CAAC,CAAC,CACL,CAAC;IACN,CAAC,CAAC;IACF,OAAOP,eAAe;EAC1B;AACJ;AACAX,OAAO,CAACE,uBAAuB,GAAGA,uBAAuB"},"metadata":{},"sourceType":"script","externalDependencies":[]}